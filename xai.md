# 인공지능 윤리와 xai

## 1. 트롤리 딜레마

> - 소수를 희생시켜서 다수를 살려야되는 경우에 어떤 선택을 할 것인가?
> - ai분야에도 적용이됨 (ex. 자율주행)

## 2. 인공지능의 사회적 윤리

> - 채팅으로 학습을 하는 챗봇 '테이'
> - 욕설이나 차별적인 단어들에 대해서 필터링없이 그대로 학습하게 되어서 인공지능의 역효과를 낼 수 있음을 보여준 사례

## 3. 편향

> - 학습시키는 자의 성향이 ai에 투영되어 편향된 결과값을 내놓을 수 있음
> - 원인
>   - 편향된 데이터셋 학습 : MS 챗봇 '테이'
>   - 데이터 가공과정 편향성 : 자동응시자 평가시스템 (백인, 국적 우대)
>   - 알고리즘 모델 편향성 : 늑대 vs 시베리안 허스키 구분 (늑대사진 뒤에 있는 배경으로 판단한 경우)
>   - 데이터 수집주체 편향 : 트위터, 페이스 등에 내재된 알고리즘의 편향성 존재여부 파악이 힘듬
> - 분석을 하기 전에 데이터자체가 오염되지 않았는지 파악하는 것이 정말 중요한 작업임

## 통계, 머신러닝, 딥러닝

> - 통계와 머신러닝의 차이점 : 설명에 대한 중요도가 다름
>
>   - 통계
>     - sample을 뽑아서 모수를 예측하는 것임
>     - sampling data와 모수와 얼마나 유사한 것인가 설명하는 것이 중요함
>   - 머신러닝
>     - 모수를 다 넣어서 분류와 예측을 진행함
>     - 그러다보니 따로 무엇인가를 설명할 이유가 없음
>     - 정확도가 중요해짐
>
> - 머신러닝과 딥러닝의 차이점 : data를 학습하는 방식에 차이가 존재함
>
>   - 머신러닝
>
>     - Data -> **Feature selection** -> 학습
>     - Feature  selection에 따라서 결과값이 크게 차이남 (변수를 어떻게 찾는지가 중요함)
>     - 통계기반으로 분류하고 예측하는 수준
>     - R만 사용해도 충분함  
>
>   - 딥러닝
>
>     - Data -> 학습
>     - 자체 알고리즘에 Feature selection 기능이 포함되어 있음
>
>     - 결과값이 나오지만 왜 나왔는지는 모르기 때문에 BlackBox모델임
>
>     - 분류, 예측 + '생성'을 함
>     - pythom + coding 능력 필요함

## 4. XAI (설명가능한 인공지능)

> - BlackBox가 아니라 WhiteBox로 만들어서 결과를 도출해낸 과정을 볼 수 있도록 만든 AI
> - 즉, 인공지능의 행위와 판단을 사람이 이해할 수 있는 형태로 설명할 수 있는 인공지능
>   - 각 노드별로 설명라벨을 붙이는 방식
>   - 의사결정트리와 연계해서 모델을 만드는 방법
>   - 모델과 병렬적으로 실행하여 비슷한 결과가 나오면 그 모델을 사용했을 것이라고 파악하는 방법
> - AI의 예측결과에 신뢰성을 부여
>   - 자동화된 의사결정 제한, 설명을 요구할 권리 처럼 산업에 적용될 때에는 신뢰성이 중요해질 것임
> - 중요요소
>   - 설명성 (Explainability)
>   - 해석성 (Interpreterability)
> - 사람의 학습과정
>   - 직관
>     - 물리적직관
>     - 심리적직관
>   - 모델을 빠르게 구축
>     - 조합
>     - 인과관계
>     - 적용